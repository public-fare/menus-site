{
 "metadata": {
  "name": "",
  "signature": "sha256:b4349aa88d3fab98b6f6a90e9ac84cc489ec2a3a1009aac9f1190b78d78c3caa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Cleaning Up Dish Names Using Fingerprint Clustering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "by Trevor Mu\u00f1oz, [@trevormunoz](https://twitter.com/trevormunoz)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls ../data/dishes/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dishes_1851_to_1921-use_this_in_refine.csv dishes_1851_to_1921_fingerprinted.csv\r\n",
        "dishes_1851_to_1921.csv\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df = pd.DataFrame.from_csv('../data/dishes/dishes_1851_to_1921.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>description</th>\n",
        "      <th>menus_appeared</th>\n",
        "      <th>times_appeared</th>\n",
        "      <th>first_appeared</th>\n",
        "      <th>last_appeared</th>\n",
        "      <th>lowest_price</th>\n",
        "      <th>highest_price</th>\n",
        "      <th>name_modified</th>\n",
        "      <th>fingerprint</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Consomme printaniere royal</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  10</td>\n",
        "      <td>  10</td>\n",
        "      <td> 1897</td>\n",
        "      <td> 1927</td>\n",
        "      <td> 0.2</td>\n",
        "      <td> 0.4</td>\n",
        "      <td> consomme printaniere royal</td>\n",
        "      <td> consomme printaniere royal</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>              Chicken gumbo</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 109</td>\n",
        "      <td> 115</td>\n",
        "      <td> 1895</td>\n",
        "      <td> 1960</td>\n",
        "      <td> 0.1</td>\n",
        "      <td> 0.8</td>\n",
        "      <td>              chicken gumbo</td>\n",
        "      <td>              chicken gumbo</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                          name  description  menus_appeared  times_appeared  \\\n",
        "id                                                                            \n",
        "1   Consomme printaniere royal          NaN              10              10   \n",
        "2                Chicken gumbo          NaN             109             115   \n",
        "\n",
        "    first_appeared  last_appeared  lowest_price  highest_price  \\\n",
        "id                                                               \n",
        "1             1897           1927           0.2            0.4   \n",
        "2             1895           1960           0.1            0.8   \n",
        "\n",
        "                 name_modified                 fingerprint  \n",
        "id                                                          \n",
        "1   consomme printaniere royal  consomme printaniere royal  \n",
        "2                chicken gumbo               chicken gumbo  \n",
        "\n",
        "[2 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "138596\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At the outset, it appears that there are 141,781 unique values for dish names in the set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def fingerprint(x):\n",
      "    \"\"\"\n",
      "    A modified version of the fingerprint clustering algorithm implemented by Open Refine.\n",
      "    See https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth\n",
      "    This does not normalize to ASCII characters since diacritics may be significant in this dataset\n",
      "    \"\"\"\n",
      "    alphanumeric_tokens = filter(None, re.split('\\W', x))\n",
      "    seen = set()\n",
      "    seen_add = seen.add\n",
      "    deduped = sorted([i for i in alphanumeric_tokens if i not in seen and not seen_add(i)])\n",
      "    fingerprint = ' '.join(deduped)\n",
      "    \n",
      "    return fingerprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df['fingerprint'] = dishes_df.name_modified.map(fingerprint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>name</th>\n",
        "      <th>description</th>\n",
        "      <th>menus_appeared</th>\n",
        "      <th>times_appeared</th>\n",
        "      <th>first_appeared</th>\n",
        "      <th>last_appeared</th>\n",
        "      <th>lowest_price</th>\n",
        "      <th>highest_price</th>\n",
        "      <th>name_modified</th>\n",
        "      <th>fingerprint</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>id</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> Consomme printaniere royal</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  10</td>\n",
        "      <td>  10</td>\n",
        "      <td> 1897</td>\n",
        "      <td> 1927</td>\n",
        "      <td> 0.20</td>\n",
        "      <td>  0.4</td>\n",
        "      <td> consomme printaniere royal</td>\n",
        "      <td> consomme printaniere royal</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>              Chicken gumbo</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 109</td>\n",
        "      <td> 115</td>\n",
        "      <td> 1895</td>\n",
        "      <td> 1960</td>\n",
        "      <td> 0.10</td>\n",
        "      <td>  0.8</td>\n",
        "      <td>              chicken gumbo</td>\n",
        "      <td>              chicken gumbo</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>        Tomato aux croutons</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  15</td>\n",
        "      <td>  15</td>\n",
        "      <td> 1893</td>\n",
        "      <td> 1917</td>\n",
        "      <td> 0.25</td>\n",
        "      <td>  0.4</td>\n",
        "      <td>        tomato aux croutons</td>\n",
        "      <td>        aux croutons tomato</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>            Onion au gratin</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  41</td>\n",
        "      <td>  41</td>\n",
        "      <td> 1900</td>\n",
        "      <td> 1971</td>\n",
        "      <td> 0.35</td>\n",
        "      <td>  1.0</td>\n",
        "      <td>            onion au gratin</td>\n",
        "      <td>            au gratin onion</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>                St. Emilion</td>\n",
        "      <td>NaN</td>\n",
        "      <td>  62</td>\n",
        "      <td>  64</td>\n",
        "      <td> 1881</td>\n",
        "      <td> 1981</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 18.0</td>\n",
        "      <td>                st. emilion</td>\n",
        "      <td>                 emilion st</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "                          name  description  menus_appeared  times_appeared  \\\n",
        "id                                                                            \n",
        "1   Consomme printaniere royal          NaN              10              10   \n",
        "2                Chicken gumbo          NaN             109             115   \n",
        "3          Tomato aux croutons          NaN              15              15   \n",
        "4              Onion au gratin          NaN              41              41   \n",
        "5                  St. Emilion          NaN              62              64   \n",
        "\n",
        "    first_appeared  last_appeared  lowest_price  highest_price  \\\n",
        "id                                                               \n",
        "1             1897           1927          0.20            0.4   \n",
        "2             1895           1960          0.10            0.8   \n",
        "3             1893           1917          0.25            0.4   \n",
        "4             1900           1971          0.35            1.0   \n",
        "5             1881           1981          0.00           18.0   \n",
        "\n",
        "                 name_modified                 fingerprint  \n",
        "id                                                          \n",
        "1   consomme printaniere royal  consomme printaniere royal  \n",
        "2                chicken gumbo               chicken gumbo  \n",
        "3          tomato aux croutons         aux croutons tomato  \n",
        "4              onion au gratin             au gratin onion  \n",
        "5                  st. emilion                  emilion st  \n",
        "\n",
        "[5 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can cluster by these fingerprint values \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters = dishes_df.groupby('fingerprint')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = clusters.size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s.order()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "fingerprint\n",
        "0 00 1 50 addition cups in of pint price quart to wine    1\n",
        "0 00 1 50 box cigarettes franc large per size small       1\n",
        "0 00 1 50 box cigarettes francs large per size small      1\n",
        "0 00 1 60 c germaine gorge l macon s                      1\n",
        "0 05 clam cocktail extra or oysters                       1\n",
        "0 1 2 50 75 bottle munich tivoli                          1\n",
        "0 1 2 50 american bottle lager                            1\n",
        "0 1 2 50 bottle lager tivoli                              1\n",
        "0 1 2 50 bottle soda                                      1\n",
        "0 1 2 60 apollinaris bottle                               1\n",
        "0 1 2 75 ale bass bottle                                  1\n",
        "0 1 2 75 ale belfast bottle ginger                        1\n",
        "0 1 2 75 bottle guiness porter                            1\n",
        "0 1 25 75 and barton c guestier julien s st               1\n",
        "0 1 50 75 claret julien pts qts st                        1\n",
        "...\n",
        "beef cold corned                      33\n",
        "french fried potatoes                 33\n",
        "grapefruit half                       34\n",
        "champagne chandon mo seal t white     35\n",
        "fried potatoes sweet                  35\n",
        "eggs scrambled                        36\n",
        "boiled potatoes                       38\n",
        "clear green soup turtle               39\n",
        "cream hashed in potatoes              39\n",
        "clams little neck                     41\n",
        "2 eggs fried                          45\n",
        "2 boiled eggs                         47\n",
        "2 eggs on poached toast               50\n",
        "brown hashed potatoes                 57\n",
        "champagne co dry extra g h mumm s    119\n",
        "Length: 119633, dtype: int64"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before making any further changes to the data, we'll save a copy of the dish data that includes the fingerprint:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.to_csv('../data/dishes/dishes_1851_to_1921_fingerprinted.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's assess the scope of variance in sizes of clusters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "1      100826\n",
        "2       11617\n",
        "3        3478\n",
        "4        1511\n",
        "5         833\n",
        "6         458\n",
        "7         256\n",
        "8         179\n",
        "9         119\n",
        "10         84\n",
        "11         61\n",
        "12         45\n",
        "13         27\n",
        "14         22\n",
        "15         12\n",
        "16         12\n",
        "17         12\n",
        "19          9\n",
        "18          9\n",
        "22          8\n",
        "21          6\n",
        "27          5\n",
        "23          5\n",
        "24          4\n",
        "20          4\n",
        "31          3\n",
        "33          3\n",
        "28          3\n",
        "39          2\n",
        "35          2\n",
        "32          2\n",
        "30          2\n",
        "26          2\n",
        "25          2\n",
        "29          1\n",
        "34          1\n",
        "36          1\n",
        "38          1\n",
        "119         1\n",
        "41          1\n",
        "45          1\n",
        "47          1\n",
        "50          1\n",
        "57          1\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, there are about 100,000 singletons (clusters of size 1), but if we consider clusters of size 5 and greater, the number drops pretty far."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clusters_5_and_greater = clusters.size() >= 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(s[clusters_5_and_greater].order())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "2201"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Two Experiments with Using Clusters to Refine Names"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a slice that represents the top 10 largest clusters and experiment with cleaning that up \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "top_10_hits = [val for val in s[clusters_5_and_greater].order()[-10:].index]\n",
      "print(top_10_hits)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_top_10_df = dishes_df[dishes_df.fingerprint.isin(top_10_hits)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_top_10_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_top_10_df.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This small sample has ostensibly 181 unique name values. Let's see if using Google Refine, we can reduce that number to 10. (If names share a fingerprint, we're going to assume they should be normalized to the same value.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_top_10_df.to_csv('/Users/libraries/Downloads/cleaning_sample_dishes.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load up what we get back after using Refine \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refined = pd.DataFrame.from_csv('/Users/libraries/Downloads/cleaning_sample_dishes-refined.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refined.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refined.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There &mdash; we've reduced the variation down to 10 unique values. Let's update our main dataframe with the new values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.name_modified.update(refined.name_modified)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df[dishes_df.index == 219]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t1 = dishes_df.name_modified.nunique()\n",
      "print(unique_dish_names_t1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t0 - unique_dish_names_t1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now it appears, our count of unique values for dish name is down 172 to only 141,609. Let's take another set of clusters and try a second method that doesn't require heading out to Open Refine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "second_sample = [val for val in s[clusters_5_and_greater].order()[-30:-11].index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "second_sample_df = dishes_df[dishes_df.fingerprint.isin(second_sample)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for item in second_sample:\n",
      "    print(item)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use the fingerprints, to directly set up a mapping. Here we're just going to assert what the value of name ought to be based on particular fingerprint without the interactive procedure of refining variant values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "updates = {\n",
      "'fruit grape half' : 'grapefruit, half',\n",
      "'lettuce salad' : 'salad, lettuce',\n",
      "'lobster salad' : 'salad, lobster',\n",
      "'brown hashed potatoes' : 'potatoes, hashed brown',\n",
      "'chocolate cream ice' : 'ice cream, chocolate',\n",
      "'co dry extra g h mumm s' : \"champagne, g. h. mumm's & co. (extra dry)\", \n",
      "'cream in potatoes stewed' : 'potatoes, stewed in cream',\n",
      "'clear green soup turtle' : 'soup, clear green turtle',\n",
      "'cream ice strawberry' : 'ice cream, strawberry',\n",
      "'grilled potatoes sweet' : 'sweet potatoes, grilled',\n",
      "'baked potatoes' : 'potatoes, baked',\n",
      "'clams little necks' : 'clams, little neck',\n",
      "'lyonnaise potatoes' : 'potatoes, lyonnaise',\n",
      "'ale bass dog head s' : \"ale, bass dog's head\",\n",
      "'boiled eggs two' : 'eggs, boiled (2)',\n",
      "'au gratin potatoes' : 'potatoes, au gratin',\n",
      "'browned hashed potatoes' : 'potatoes, hashed brown',\n",
      "'co dry extra g h mumm' : \"champagne, g. h. mumm's & co. (extra dry)\",\n",
      "'cream ice vanilla' : 'ice cream, vanilla'\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The keys of this dictionary are the algorithmically-generated fingerprints"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "updates.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For each key, we'll create a temporary dataframe of just the corresponding rows, then use our mapping to create a column with the canonical value corresponding to each key and finally update the main dataframe with the new value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in updates.keys():\n",
      "    temp_df = second_sample_df[second_sample_df.fingerprint == k]\n",
      "    temp_df['canonical'] = temp_df.fingerprint.map(updates)\n",
      "    dishes_df.name_modified = temp_df.canonical.combine_first(dishes_df.name_modified)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t2 = dishes_df.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t1 - unique_dish_names_t2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After this, our count of unique values just dropped by over 200. We can check that our updates worked as expected by inspecting rows with one of the fingerprint values from our sample \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df[dishes_df.fingerprint =='grilled potatoes sweet']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's save out a copy of this partially-corrected data \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.to_csv('../data/dishes/dishes_1851_to_1921.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "third_sample = second_sample = [val for val in s[clusters_5_and_greater].order()[:-31].index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(third_sample)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "third_sample_df = dishes_df[dishes_df.fingerprint.isin(third_sample)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "third_sample_df.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "third_sample_df.to_csv('/Users/libraries/Downloads/third_refine_sample.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Out to Open Refine and back \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "more_refined = pd.DataFrame.from_csv('/Users/libraries/Downloads/third_refine_sample-cleaned.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "more_refined.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "more_refined.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.name_modified.update(more_refined.name_modified)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t3 = dishes_df.name_modified.nunique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t2-unique_dish_names_t3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This latest round of data clean up reduced the number of unique names in the data set by almost 2800."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t0-unique_dish_names_t3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the first round of normalization above, the number of unique values is down over 3,000"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Save out a copy of progress to this point \u2026"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dishes_df.to_csv('../data/dishes/dishes_1851_to_1921.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point, there look to be about 138,500 unique names left. From inspecting the size of the clusters above, we know that there are almost 100,100 singleton values (not amenable to improvement via clustering) so this is a far more manageable number than it seems."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_dish_names_t3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}